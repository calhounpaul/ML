"""
INFO:__main__:
Analyzing dataset: simsamu
INFO:__main__:Dataset length: 61
INFO:__main__:First item structure:
INFO:__main__:  Analyzing field: audio
INFO:__main__:  Detailed audio analysis:
INFO:__main__:    Audio key: path
INFO:__main__:    Audio key type: <class 'str'>
INFO:__main__:    Audio key: array
INFO:__main__:    Audio key type: <class 'numpy.ndarray'>
INFO:__main__:    Array shape: (4823040,)
INFO:__main__:    Array dtype: float64
INFO:__main__:    Audio key: sampling_rate
INFO:__main__:    Audio key type: <class 'int'>
INFO:__main__:  Analyzing field: timestamps_start
INFO:__main__:  Analyzing field: timestamps_end
INFO:__main__:  Analyzing field: speakers
INFO:__main__:
Checking field consistency across items:
INFO:__main__:
Field: audio
INFO:__main__:  Item 0:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:  Item 1:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:  Item 2:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:  Item 3:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:  Item 4:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:
Field: timestamps_start
INFO:__main__:  Item 0:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 80
INFO:__main__:  Item 1:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 79
INFO:__main__:  Item 2:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 37
INFO:__main__:  Item 3:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 40
INFO:__main__:  Item 4:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 28
INFO:__main__:
Field: timestamps_end
INFO:__main__:  Item 0:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 80
INFO:__main__:  Item 1:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 79
INFO:__main__:  Item 2:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 37
INFO:__main__:  Item 3:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 40
INFO:__main__:  Item 4:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 28
INFO:__main__:
Field: speakers
INFO:__main__:  Item 0:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 80
INFO:__main__:  Item 1:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 79
INFO:__main__:  Item 2:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 37
INFO:__main__:  Item 3:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 40
INFO:__main__:  Item 4:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 28
INFO:__main__:
Detailed analysis saved to dataset_analysis_simsamu.json
INFO:__main__:
Analyzing dataset: callhome_deu
INFO:__main__:Dataset length: 120
INFO:__main__:First item structure:
INFO:__main__:  Analyzing field: audio
INFO:__main__:  Detailed audio analysis:
INFO:__main__:    Audio key: path
INFO:__main__:    Audio key type: <class 'NoneType'>
INFO:__main__:    Audio key: array
INFO:__main__:    Audio key type: <class 'numpy.ndarray'>
INFO:__main__:    Array shape: (9630080,)
INFO:__main__:    Array dtype: float64
INFO:__main__:    Audio key: sampling_rate
INFO:__main__:    Audio key type: <class 'int'>
INFO:__main__:  Analyzing field: timestamps_start
INFO:__main__:  Analyzing field: timestamps_end
INFO:__main__:  Analyzing field: speakers
INFO:__main__:
Checking field consistency across items:
INFO:__main__:
Field: audio
INFO:__main__:  Item 0:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:  Item 1:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:  Item 2:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:  Item 3:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:  Item 4:
INFO:__main__:    Type: <class 'dict'>
INFO:__main__:    Keys: ['path', 'array', 'sampling_rate']
INFO:__main__:
Field: timestamps_start
INFO:__main__:  Item 0:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 248
INFO:__main__:  Item 1:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 263
INFO:__main__:  Item 2:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 211
INFO:__main__:  Item 3:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 347
INFO:__main__:  Item 4:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 177
INFO:__main__:
Field: timestamps_end
INFO:__main__:  Item 0:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 248
INFO:__main__:  Item 1:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 263
INFO:__main__:  Item 2:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 211
INFO:__main__:  Item 3:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 347
INFO:__main__:  Item 4:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 177
INFO:__main__:
Field: speakers
INFO:__main__:  Item 0:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 248
INFO:__main__:  Item 1:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 263
INFO:__main__:  Item 2:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 211
INFO:__main__:  Item 3:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 347
INFO:__main__:  Item 4:
INFO:__main__:    Type: <class 'list'>
INFO:__main__:    Length: 177
INFO:__main__:
Detailed analysis saved to dataset_analysis_callhome_deu.json

"""


from datasets import load_dataset
import numpy as np
import logging
from typing import Any, Dict, List
import json

logging.basicConfig(level=logging.INFO, filename='analyze.log', filemode='w')
logger = logging.getLogger(__name__)

def inspect_value(value: Any, depth: int = 0, max_depth: int = 3) -> Dict:
    """Recursively inspect a value's structure and properties."""
    if depth >= max_depth:
        return {
            'type': str(type(value)),
            'truncated': True
        }
        
    structure = {
        'type': str(type(value)),
        'length': len(value) if hasattr(value, '__len__') else None,
    }
    
    if isinstance(value, dict):
        structure['keys'] = list(value.keys())
        structure['value_samples'] = {
            k: inspect_value(v, depth + 1, max_depth) 
            for k, v in list(value.items())[:3]  # Sample first 3 items
        }
    elif isinstance(value, (list, tuple, np.ndarray)):
        structure['sample_values'] = [
            inspect_value(v, depth + 1, max_depth) 
            for v in value[:3]  # Sample first 3 items
        ]
        if isinstance(value, np.ndarray):
            structure['shape'] = value.shape
            structure['dtype'] = str(value.dtype)
    
    # Include additional attributes
    if hasattr(value, '__dict__'):
        attrs = dir(value)
        public_attrs = [attr for attr in attrs if not attr.startswith('_')]
        structure['attributes'] = public_attrs
        
    return structure

def analyze_dataset_item(item: Dict, prefix: str = '') -> Dict:
    """Analyze the structure of a dataset item."""
    analysis = {}
    
    for key, value in item.items():
        logger.info(f"{prefix}Analyzing field: {key}")
        analysis[key] = inspect_value(value)
        
        if key == 'audio':
            logger.info(f"{prefix}Detailed audio analysis:")
            try:
                if hasattr(value, 'keys'):
                    for audio_key in value.keys():
                        logger.info(f"{prefix}  Audio key: {audio_key}")
                        logger.info(f"{prefix}  Audio key type: {type(value[audio_key])}")
                        if isinstance(value[audio_key], np.ndarray):
                            logger.info(f"{prefix}  Array shape: {value[audio_key].shape}")
                            logger.info(f"{prefix}  Array dtype: {value[audio_key].dtype}")
            except Exception as e:
                logger.error(f"{prefix}Error analyzing audio: {e}")
    
    return analysis

def analyze_dataset(name: str, path: str, split: str, data_split: str = None):
    """Load and analyze a dataset's structure."""
    logger.info(f"\nAnalyzing dataset: {name}")
    
    try:
        # Load dataset
        if data_split:
            dataset = load_dataset(path, split, split=data_split)
        else:
            dataset = load_dataset(path, split=split)
            
        logger.info(f"Dataset length: {len(dataset)}")
        
        # Analyze first item in detail
        first_item = dataset[0]
        logger.info("First item structure:")
        analysis = analyze_dataset_item(first_item, prefix='  ')
        
        # Analyze a few more items for consistency
        logger.info("\nChecking field consistency across items:")
        sample_indices = list(range(min(5, len(dataset))))
        
        for field in first_item.keys():
            logger.info(f"\nField: {field}")
            for idx in sample_indices:
                item = dataset[idx]
                logger.info(f"  Item {idx}:")
                logger.info(f"    Type: {type(item[field])}")
                if hasattr(item[field], 'keys'):
                    logger.info(f"    Keys: {list(item[field].keys())}")
                if isinstance(item[field], (list, np.ndarray)):
                    logger.info(f"    Length: {len(item[field])}")
                
        # Save analysis to file
        output_file = f"dataset_analysis_{name}.json"
        with open(output_file, 'w') as f:
            json.dump(analysis, f, indent=2)
        logger.info(f"\nDetailed analysis saved to {output_file}")
        
    except Exception as e:
        logger.error(f"Error analyzing dataset {name}: {e}")

def main():
    """Analyze all relevant datasets."""
    datasets = {
        'simsamu': ('diarizers-community/simsamu', 'train', None),
        'callhome_deu': ('talkbank/callhome', 'deu', 'data')
    }
    
    for name, (path, split, data_split) in datasets.items():
        analyze_dataset(name, path, split, data_split)

if __name__ == "__main__":
    main()